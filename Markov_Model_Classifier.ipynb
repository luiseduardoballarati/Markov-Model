{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLcYGavJNg05",
        "outputId": "c25c37e2-2e59-4140-e35c-cd480b55fe8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-13 19:08:24--  https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/edgar_allan_poe.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26622 (26K) [text/plain]\n",
            "Saving to: ‘edgar_allan_poe.txt’\n",
            "\n",
            "edgar_allan_poe.txt 100%[===================>]  26.00K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-03-13 19:08:24 (18.3 MB/s) - ‘edgar_allan_poe.txt’ saved [26622/26622]\n",
            "\n",
            "--2024-03-13 19:08:24--  https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 56286 (55K) [text/plain]\n",
            "Saving to: ‘robert_frost.txt’\n",
            "\n",
            "robert_frost.txt    100%[===================>]  54.97K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-03-13 19:08:24 (4.80 MB/s) - ‘robert_frost.txt’ saved [56286/56286]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/edgar_allan_poe.txt\n",
        "!wget -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "1vsiorrZN0t2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_files = [\n",
        "    'edgar_allan_poe.txt',\n",
        "    'robert_frost.txt'\n",
        "]"
      ],
      "metadata": {
        "id": "YAn0VweLN8u9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head edgar_allan_poe.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHNSzG6YODQR",
        "outputId": "88af5b41-f2d6-4474-c7e4-7c4a36d73a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LO! Death hath rear'd himself a throne\n",
            "In a strange city, all alone,\n",
            "Far down within the dim west\n",
            "Where the good, and the bad, and the worst, and the best,\n",
            "Have gone to their eternal rest.\n",
            " \n",
            "There shrines, and palaces, and towers\n",
            "Are not like any thing of ours\n",
            "Oh no! O no! ours never loom\n",
            "To heaven with that ungodly gloom!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head robert_frost.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMdeIcbwOhrP",
        "outputId": "7b628293-efd5-4ff0-ce3d-b267182a16a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Two roads diverged in a yellow wood,\n",
            "And sorry I could not travel both\n",
            "And be one traveler, long I stood\n",
            "And looked down one as far as I could\n",
            "To where it bent in the undergrowth; \n",
            "\n",
            "Then took the other, as just as fair,\n",
            "And having perhaps the better claim\n",
            "Because it was grassy and wanted wear,\n",
            "Though as for that the passing there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are treating each line as an input sample. This is opposed to an entire verse or an entire poem, so we will begin by creating two empty lists, one to hold the text and the other the label."
      ],
      "metadata": {
        "id": "T32xfLeyPQ5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# collect data into lists\n",
        "input_texts = []\n",
        "labels = []\n",
        "\n",
        "# loop through each input file\n",
        "for label, f in enumerate(input_files):\n",
        "  print(f\"{f} correspondes to label {label}\")\n",
        "\n",
        "  for line in open(f):\n",
        "    line = line.rstrip().lower()\n",
        "    if line:\n",
        "      # remove punctuation\n",
        "      line = line.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "      input_texts.append(line)\n",
        "      labels.append(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCj6cmHNOkiO",
        "outputId": "b1ef9268-17b0-43f6-9acc-6e314188f11b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "robert_frost.txt correspondes to label 0\n",
            "edgar_allan_poe.txt correspondes to label 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_text, test_text, Ytrain, Ytest = train_test_split(input_texts, labels)"
      ],
      "metadata": {
        "id": "yaDS3om7OpYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(Ytrain), len(Ytest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwoTpF5PP0zx",
        "outputId": "873fa374-e1b2-4c3f-8524-e379325339a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1615, 539)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_text[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOMxV8pDP4x9",
        "outputId": "4983fdba-ae09-49fe-9916-55964537dcab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['if i remember rightly it had sprung',\n",
              " 'sweet flowers ere long',\n",
              " 'for the resurrection of deepburied faith',\n",
              " 'thy grief thy joy thy hate thy love',\n",
              " 'alas i cannot feel for tis not feeling']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ytrain[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOlayC2EQNG2",
        "outputId": "ae79ea95-4e4e-4654-dd11-48a910a44237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 1, 1, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step is to convert our text into integers. These will be indexes into the Markov Matrices we are about to define.\n",
        "\n",
        "We begin setting idx=1 which will act as out current index as we loop through the  text.\n",
        "\n",
        "We'll also initialize a word to index dictionary with one entry, which maps the unknown token to zero. This will never be used for the train set, but might be used for the test set if the test set contain words that do not appear in the train set."
      ],
      "metadata": {
        "id": "GIAPmUl-QiMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 1\n",
        "word2idx = {'<unk>': 0}"
      ],
      "metadata": {
        "id": "CXA1A35LP_ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# populate word2idx\n",
        "for text in train_text:\n",
        "  # split the text into tokens\n",
        "  tokens = text.split()\n",
        "  for token in tokens:\n",
        "    if token not in word2idx:\n",
        "      word2idx[token] = idx\n",
        "      idx += 1"
      ],
      "metadata": {
        "id": "RBa2e-BOQF62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jUb64sjRTyS",
        "outputId": "113ff390-506d-43d3-a7cd-66973c1f9a50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<unk>': 0,\n",
              " 'if': 1,\n",
              " 'i': 2,\n",
              " 'remember': 3,\n",
              " 'rightly': 4,\n",
              " 'it': 5,\n",
              " 'had': 6,\n",
              " 'sprung': 7,\n",
              " 'sweet': 8,\n",
              " 'flowers': 9,\n",
              " 'ere': 10,\n",
              " 'long': 11,\n",
              " 'for': 12,\n",
              " 'the': 13,\n",
              " 'resurrection': 14,\n",
              " 'of': 15,\n",
              " 'deepburied': 16,\n",
              " 'faith': 17,\n",
              " 'thy': 18,\n",
              " 'grief': 19,\n",
              " 'joy': 20,\n",
              " 'hate': 21,\n",
              " 'love': 22,\n",
              " 'alas': 23,\n",
              " 'cannot': 24,\n",
              " 'feel': 25,\n",
              " 'tis': 26,\n",
              " 'not': 27,\n",
              " 'feeling': 28,\n",
              " 'rivers': 29,\n",
              " 'glide': 30,\n",
              " 'and': 31,\n",
              " 'then': 32,\n",
              " 'you': 33,\n",
              " 'will': 34,\n",
              " 'find': 35,\n",
              " 'your': 36,\n",
              " 'money': 37,\n",
              " 'in': 38,\n",
              " 'creases': 39,\n",
              " 'now': 40,\n",
              " 'as': 41,\n",
              " 'night': 42,\n",
              " 'was': 43,\n",
              " 'senescent': 44,\n",
              " 'with': 45,\n",
              " 'whose': 46,\n",
              " 'vast': 47,\n",
              " 'wheels': 48,\n",
              " 'being': 49,\n",
              " 'cut': 50,\n",
              " 'off': 51,\n",
              " 'from': 52,\n",
              " 'friends': 53,\n",
              " 'help': 54,\n",
              " 'out': 55,\n",
              " 'this': 56,\n",
              " 'beadwork': 57,\n",
              " 'what': 58,\n",
              " 'can': 59,\n",
              " 'no': 60,\n",
              " 'holy': 61,\n",
              " 'rays': 62,\n",
              " 'heaven': 63,\n",
              " 'come': 64,\n",
              " 'down': 65,\n",
              " 'warren': 66,\n",
              " 'at': 67,\n",
              " 'march': 68,\n",
              " 'meeting': 69,\n",
              " 'reason': 70,\n",
              " 'to': 71,\n",
              " 'carry': 72,\n",
              " 'again': 73,\n",
              " 'see': 74,\n",
              " 'how': 75,\n",
              " 'they': 76,\n",
              " 'were': 77,\n",
              " 'mounted': 78,\n",
              " 'walk': 79,\n",
              " 'mother': 80,\n",
              " 'we': 81,\n",
              " 'know': 82,\n",
              " 'a': 83,\n",
              " 'grave': 84,\n",
              " 'cellar': 85,\n",
              " 'through': 86,\n",
              " 'two': 87,\n",
              " 'luminous': 88,\n",
              " 'windows': 89,\n",
              " 'saw': 90,\n",
              " 'ecstasies': 91,\n",
              " 'above': 92,\n",
              " 'ought': 93,\n",
              " 'have': 94,\n",
              " 'kitchen': 95,\n",
              " 'yourself': 96,\n",
              " 'make': 97,\n",
              " 'summer': 98,\n",
              " 'dwelling': 99,\n",
              " 'here': 100,\n",
              " 'or': 101,\n",
              " 'that': 102,\n",
              " 'thrill': 103,\n",
              " 'single': 104,\n",
              " 'kiss': 105,\n",
              " 'our': 106,\n",
              " 'arms': 107,\n",
              " 'level': 108,\n",
              " 'knees': 109,\n",
              " 'all': 110,\n",
              " 'fresh': 111,\n",
              " 'sound': 112,\n",
              " 'recent': 113,\n",
              " 'axe': 114,\n",
              " 'but': 115,\n",
              " 'didnt': 116,\n",
              " 'always': 117,\n",
              " 'once': 118,\n",
              " 'an': 119,\n",
              " 'alley': 120,\n",
              " 'titanic': 121,\n",
              " 'desolately': 122,\n",
              " 'fall': 123,\n",
              " 'do': 124,\n",
              " 'such': 125,\n",
              " 'hole': 126,\n",
              " 'wonder': 127,\n",
              " 'his': 128,\n",
              " 'journey': 129,\n",
              " 'field': 130,\n",
              " 'memories': 131,\n",
              " 'treacherous': 132,\n",
              " 'sere': 133,\n",
              " 'bones': 134,\n",
              " 'liked': 135,\n",
              " 'attic': 136,\n",
              " 'let': 137,\n",
              " 'them': 138,\n",
              " 'feared': 139,\n",
              " 'cold': 140,\n",
              " 'im': 141,\n",
              " 'waiting': 142,\n",
              " 'beauty': 143,\n",
              " 'by': 144,\n",
              " 'god': 145,\n",
              " 'those': 146,\n",
              " 'alone': 147,\n",
              " 'are': 148,\n",
              " 'my': 149,\n",
              " 'ministers': 150,\n",
              " 'yet': 151,\n",
              " 'their': 152,\n",
              " 'slave': 153,\n",
              " 'spirit': 154,\n",
              " 'knew': 155,\n",
              " 'hour': 156,\n",
              " 'boys': 157,\n",
              " 'bad': 158,\n",
              " 'hunters': 159,\n",
              " 'known': 160,\n",
              " 'made': 161,\n",
              " 'shift': 162,\n",
              " 'shelter': 163,\n",
              " 'without': 164,\n",
              " 'misty': 165,\n",
              " 'mid': 166,\n",
              " 'region': 167,\n",
              " 'weir': 168,\n",
              " 'want': 169,\n",
              " 'hear': 170,\n",
              " 'me': 171,\n",
              " 'talk': 172,\n",
              " 'groan': 173,\n",
              " 'roll': 174,\n",
              " 'mount': 175,\n",
              " 'yaanek': 176,\n",
              " 'vacuum': 177,\n",
              " 'filmy': 178,\n",
              " 'though': 179,\n",
              " 'light': 180,\n",
              " 'leaf': 181,\n",
              " 'there': 182,\n",
              " 'been': 183,\n",
              " 'one': 184,\n",
              " 'stir': 185,\n",
              " 'where': 186,\n",
              " 'achilles': 187,\n",
              " 'diomed': 188,\n",
              " 'rest': 189,\n",
              " 'hard': 190,\n",
              " 'dim': 191,\n",
              " 'lake': 192,\n",
              " 'auber': 193,\n",
              " 'until': 194,\n",
              " 'id': 195,\n",
              " 'him': 196,\n",
              " 'worn': 197,\n",
              " 'skin': 198,\n",
              " 'its': 199,\n",
              " 'sybilic': 200,\n",
              " 'splendor': 201,\n",
              " 'is': 202,\n",
              " 'beaming': 203,\n",
              " 'said': 204,\n",
              " 'arent': 205,\n",
              " 'nowadays': 206,\n",
              " 'fever': 207,\n",
              " 'minute': 208,\n",
              " 'furs': 209,\n",
              " 'sell': 210,\n",
              " 'leave': 211,\n",
              " 'tatters': 212,\n",
              " 'hung': 213,\n",
              " 'on': 214,\n",
              " 'barb': 215,\n",
              " 'thorn': 216,\n",
              " 'he': 217,\n",
              " 'bowed': 218,\n",
              " 'grace': 219,\n",
              " 'natural': 220,\n",
              " 'law': 221,\n",
              " 'neighbour': 222,\n",
              " 'just': 223,\n",
              " 'man': 224,\n",
              " 'after': 225,\n",
              " 'stay': 226,\n",
              " 'unless': 227,\n",
              " 'stove': 228,\n",
              " 'sparkling': 229,\n",
              " 'evermore': 230,\n",
              " 'cant': 231,\n",
              " 'passed': 232,\n",
              " 'each': 233,\n",
              " 'other': 234,\n",
              " 'neck': 235,\n",
              " 'thought': 236,\n",
              " 'spare': 237,\n",
              " 'clothes': 238,\n",
              " 'secret': 239,\n",
              " 'communing': 240,\n",
              " 'held': 241,\n",
              " 'hed': 242,\n",
              " 'bet': 243,\n",
              " 'huse': 244,\n",
              " 'cribber': 245,\n",
              " 'gnawed': 246,\n",
              " 'son': 247,\n",
              " 'looks': 248,\n",
              " 'surprised': 249,\n",
              " 'end': 250,\n",
              " 'lie': 251,\n",
              " 'roads': 252,\n",
              " 'diverged': 253,\n",
              " 'yellow': 254,\n",
              " 'wood': 255,\n",
              " 'lethean': 256,\n",
              " 'peace': 257,\n",
              " 'skies': 258,\n",
              " 'which': 259,\n",
              " 'came': 260,\n",
              " 'flowing': 261,\n",
              " 'greenest': 262,\n",
              " 'valleys': 263,\n",
              " 'creaking': 264,\n",
              " 'buggy': 265,\n",
              " 'load': 266,\n",
              " 'grain': 267,\n",
              " 'passionate': 268,\n",
              " 'fit': 269,\n",
              " 'up': 270,\n",
              " 'fanes': 271,\n",
              " 'babylonlike': 272,\n",
              " 'walls': 273,\n",
              " 'quickening': 274,\n",
              " 'spell': 275,\n",
              " 'doth': 276,\n",
              " 'oer': 277,\n",
              " 'us': 278,\n",
              " 'pass': 279,\n",
              " 'place': 280,\n",
              " 'kinsman': 281,\n",
              " 'still': 282,\n",
              " 'sweetly': 283,\n",
              " 'scintillant': 284,\n",
              " 'loves': 285,\n",
              " 'grownup': 286,\n",
              " 'only': 287,\n",
              " 'fault': 288,\n",
              " 'husband': 289,\n",
              " 'found': 290,\n",
              " 'listened': 291,\n",
              " 'till': 292,\n",
              " 'almost': 293,\n",
              " 'climbed': 294,\n",
              " 'stairs': 295,\n",
              " 'who': 296,\n",
              " 'pens': 297,\n",
              " 'thrills': 298,\n",
              " 'think': 299,\n",
              " 'pretty': 300,\n",
              " 'things': 301,\n",
              " 'outdoors': 302,\n",
              " 'name': 303,\n",
              " 'stark': 304,\n",
              " 'gathered': 305,\n",
              " 'bow': 306,\n",
              " 'thus': 307,\n",
              " 'pacified': 308,\n",
              " 'psyche': 309,\n",
              " 'kissed': 310,\n",
              " 'her': 311,\n",
              " 'flickers': 312,\n",
              " 'sky': 313,\n",
              " 'couldnt': 314,\n",
              " 'call': 315,\n",
              " 'living': 316,\n",
              " 'aint': 317,\n",
              " 'winter': 318,\n",
              " 'evening': 319,\n",
              " 'something': 320,\n",
              " 'must': 321,\n",
              " 'learned': 322,\n",
              " 'riding': 323,\n",
              " 'trains': 324,\n",
              " 'thrones': 325,\n",
              " 'longforgotten': 326,\n",
              " 'bowers': 327,\n",
              " 'eyes': 328,\n",
              " 'town': 329,\n",
              " 'more': 330,\n",
              " 'moonbeam': 331,\n",
              " 'hangs': 332,\n",
              " 'married': 333,\n",
              " 'thats': 334,\n",
              " 'has': 335,\n",
              " 'papered': 336,\n",
              " 'wheres': 337,\n",
              " 'john': 338,\n",
              " 'strange': 339,\n",
              " 'harpstring': 340,\n",
              " 'broken': 341,\n",
              " 'counting': 342,\n",
              " 'dinners': 343,\n",
              " 'hill': 344,\n",
              " 'many': 345,\n",
              " 'seen': 346,\n",
              " 'worth': 347,\n",
              " 'lifes': 348,\n",
              " 'while': 349,\n",
              " 'wake': 350,\n",
              " 'sport': 351,\n",
              " 'word': 352,\n",
              " 'safely': 353,\n",
              " 'may': 354,\n",
              " 'trust': 355,\n",
              " 'gleaming': 356,\n",
              " 'lipbegotten': 357,\n",
              " 'words': 358,\n",
              " 'blew': 359,\n",
              " 'icy': 360,\n",
              " 'crust': 361,\n",
              " 'means': 362,\n",
              " 'seven': 363,\n",
              " 'caves': 364,\n",
              " 'window': 365,\n",
              " 'glass': 366,\n",
              " 'quarrel': 367,\n",
              " 'about': 368,\n",
              " 'property': 369,\n",
              " 'over': 370,\n",
              " 'houses': 371,\n",
              " 'another': 372,\n",
              " 'street': 373,\n",
              " 'o': 374,\n",
              " 'hyacinthine': 375,\n",
              " 'isle': 376,\n",
              " 'purple': 377,\n",
              " 'zante': 378,\n",
              " 'pipes': 379,\n",
              " 'smoking': 380,\n",
              " 'jug': 381,\n",
              " 'smash': 382,\n",
              " 'take': 383,\n",
              " 'when': 384,\n",
              " 'youre': 385,\n",
              " 'gone': 386,\n",
              " 'say': 387,\n",
              " 'why': 388,\n",
              " 'should': 389,\n",
              " 'than': 390,\n",
              " 'round': 391,\n",
              " 'home': 392,\n",
              " 'glory': 393,\n",
              " 'tell': 394,\n",
              " 'get': 395,\n",
              " 'door': 396,\n",
              " 'troubling': 397,\n",
              " 'granny': 398,\n",
              " 'brought': 399,\n",
              " 'some': 400,\n",
              " 'publisher': 401,\n",
              " 'dew': 402,\n",
              " 'time': 403,\n",
              " 'grass': 404,\n",
              " 'whats': 405,\n",
              " 'cypress': 406,\n",
              " 'soul': 407,\n",
              " 'mighty': 408,\n",
              " 'old': 409,\n",
              " 'furthest': 410,\n",
              " 'bodies': 411,\n",
              " 'went': 412,\n",
              " 'way': 413,\n",
              " 'house': 414,\n",
              " 'seek': 415,\n",
              " 'treasure': 416,\n",
              " 'jewelled': 417,\n",
              " 'entertain': 418,\n",
              " 'birds': 419,\n",
              " 'hold': 420,\n",
              " 'upon': 421,\n",
              " 'faroff': 422,\n",
              " 'happier': 423,\n",
              " 'sea': 424,\n",
              " 'isola': 425,\n",
              " 'doro': 426,\n",
              " 'fior': 427,\n",
              " 'di': 428,\n",
              " 'levante': 429,\n",
              " 'merry': 430,\n",
              " 'little': 431,\n",
              " 'throats': 432,\n",
              " 'athens': 433,\n",
              " 'deliverance': 434,\n",
              " 'gave': 435,\n",
              " 'towers': 436,\n",
              " 'thrown': 437,\n",
              " 'aside': 438,\n",
              " 'right': 439,\n",
              " 'past': 440,\n",
              " 'both': 441,\n",
              " 'father': 442,\n",
              " 'neither': 443,\n",
              " 'stopped': 444,\n",
              " 'marked': 445,\n",
              " 'year': 446,\n",
              " 'hours': 447,\n",
              " 'sinners': 448,\n",
              " 'sacrifice': 449,\n",
              " 'steps': 450,\n",
              " 'began': 451,\n",
              " 'climb': 452,\n",
              " 'suddenly': 453,\n",
              " 'into': 454,\n",
              " 'poetess': 455,\n",
              " 'sighed': 456,\n",
              " 'enough': 457,\n",
              " 'among': 458,\n",
              " 'unearthed': 459,\n",
              " 'potatoes': 460,\n",
              " 'standing': 461,\n",
              " 'embalmed': 462,\n",
              " 'echoing': 463,\n",
              " 'songs': 464,\n",
              " 'coming': 465,\n",
              " 'choice': 466,\n",
              " 'somewhere': 467,\n",
              " 'ages': 468,\n",
              " 'hence': 469,\n",
              " 'sun': 470,\n",
              " 'stars': 471,\n",
              " 'whence': 472,\n",
              " 'drawn': 473,\n",
              " 'forth': 474,\n",
              " 'guessed': 475,\n",
              " 'theyd': 476,\n",
              " 'put': 477,\n",
              " 'looked': 478,\n",
              " 'toward': 479,\n",
              " 'against': 480,\n",
              " 'blue': 481,\n",
              " 'january': 482,\n",
              " 'thaw': 483,\n",
              " 'bedroom': 484,\n",
              " 'nonsense': 485,\n",
              " 'she': 486,\n",
              " 'done': 487,\n",
              " 'happen': 488,\n",
              " 'prefer': 489,\n",
              " 'live': 490,\n",
              " 'ghoulhaunted': 491,\n",
              " 'woodland': 492,\n",
              " 'science': 493,\n",
              " 'true': 494,\n",
              " 'daughter': 495,\n",
              " 'thou': 496,\n",
              " 'art': 497,\n",
              " 'behind': 498,\n",
              " 'mountains': 499,\n",
              " 'tempted': 500,\n",
              " 'gloom': 501,\n",
              " 'founts': 502,\n",
              " 'bliss': 503,\n",
              " 'well': 504,\n",
              " 'guess': 505,\n",
              " 'youd': 506,\n",
              " 'fountain': 507,\n",
              " 'empty': 508,\n",
              " 'state': 509,\n",
              " 'befitting': 510,\n",
              " 'warmer': 511,\n",
              " 'dian': 512,\n",
              " 'softmurmured': 513,\n",
              " 'be': 514,\n",
              " 'mean': 515,\n",
              " 'shes': 516,\n",
              " 'someone': 517,\n",
              " 'else': 518,\n",
              " 'sulphurous': 519,\n",
              " 'currents': 520,\n",
              " 'box': 521,\n",
              " 'away': 522,\n",
              " 'having': 523,\n",
              " 'interfered': 524,\n",
              " 'business': 525,\n",
              " 'whom': 526,\n",
              " 'gives': 527,\n",
              " 'glimpses': 528,\n",
              " 'times': 529,\n",
              " 'rule': 530,\n",
              " 'arm': 531,\n",
              " 'remoteness': 532,\n",
              " 'defied': 533,\n",
              " 'gets': 534,\n",
              " 'sort': 535,\n",
              " 'bakeshop': 536,\n",
              " 'meals': 537,\n",
              " 'together': 538,\n",
              " 'hearts': 539,\n",
              " 'passion': 540,\n",
              " 'tone': 541,\n",
              " 'banked': 542,\n",
              " 'sawdust': 543,\n",
              " 'hath': 544,\n",
              " 'earth': 545,\n",
              " 'destruction': 546,\n",
              " 'ice': 547,\n",
              " 'heart': 548,\n",
              " 'grew': 549,\n",
              " 'ashen': 550,\n",
              " 'sober': 551,\n",
              " 'firsts': 552,\n",
              " 'books': 553,\n",
              " 'back': 554,\n",
              " 'slippery': 555,\n",
              " 'slope': 556,\n",
              " 'cross': 557,\n",
              " 'lots': 558,\n",
              " 'everything': 559,\n",
              " 'less': 560,\n",
              " 'astartes': 561,\n",
              " 'bediamonded': 562,\n",
              " 'crescent': 563,\n",
              " 'leaves': 564,\n",
              " 'crisped': 565,\n",
              " 'duty': 566,\n",
              " 'saved': 567,\n",
              " 'bright': 568,\n",
              " 'theres': 569,\n",
              " 'dead': 570,\n",
              " 'keeping': 571,\n",
              " 'any': 572,\n",
              " 'trouble': 573,\n",
              " 'double': 574,\n",
              " 'troubles': 575,\n",
              " 'easy': 576,\n",
              " 'wind': 577,\n",
              " 'downy': 578,\n",
              " 'flake': 579,\n",
              " 'vista': 580,\n",
              " 'never': 581,\n",
              " 'seraph': 582,\n",
              " 'spread': 583,\n",
              " 'pinion': 584,\n",
              " 'worlds': 585,\n",
              " 'shall': 586,\n",
              " 'given': 587,\n",
              " 'village': 588,\n",
              " 'thee': 589,\n",
              " 'years': 590,\n",
              " 'ago': 591,\n",
              " 'extravagance': 592,\n",
              " 'young': 593,\n",
              " 'dared': 594,\n",
              " 'tiptoe': 595,\n",
              " 'venuses': 596,\n",
              " 'unextinguished': 597,\n",
              " 'stole': 598,\n",
              " 'goblet': 599,\n",
              " 'childrens': 600,\n",
              " 'playhouse': 601,\n",
              " 'toffile': 602,\n",
              " 'dont': 603,\n",
              " 'believe': 604,\n",
              " 'angel': 605,\n",
              " 'trod': 606,\n",
              " 'laurels': 607,\n",
              " 'belong': 608,\n",
              " 'stones': 609,\n",
              " 'bushes': 610,\n",
              " 'unretrieved': 611,\n",
              " 'so': 612,\n",
              " 'could': 613,\n",
              " 'recognize': 614,\n",
              " 'post': 615,\n",
              " 'early': 616,\n",
              " 'leafs': 617,\n",
              " 'flower': 618,\n",
              " 'tangle': 619,\n",
              " 'withered': 620,\n",
              " 'weeds': 621,\n",
              " 'took': 622,\n",
              " 'hall': 623,\n",
              " 'novelty': 624,\n",
              " 'literally': 625,\n",
              " 'run': 626,\n",
              " 'magical': 627,\n",
              " 'sad': 628,\n",
              " 'too': 629,\n",
              " 'i—': 630,\n",
              " 'going': 631,\n",
              " 'twice': 632,\n",
              " 'around': 633,\n",
              " 'tree': 634,\n",
              " 'burden': 635,\n",
              " 'body': 636,\n",
              " 'song': 637,\n",
              " 'note': 638,\n",
              " 'unruffled': 639,\n",
              " 'roses': 640,\n",
              " 'enchanted': 641,\n",
              " 'garden': 642,\n",
              " 'shoulders': 643,\n",
              " 'dragging': 644,\n",
              " 'strands': 645,\n",
              " 'talkedof': 646,\n",
              " 'mystery': 647,\n",
              " 'birth': 648,\n",
              " 'nighttime': 649,\n",
              " 'remembered': 650,\n",
              " 'dank': 651,\n",
              " 'tarn': 652,\n",
              " 'ever': 653,\n",
              " 'cared': 654,\n",
              " 'replied': 655,\n",
              " 'ulalume': 656,\n",
              " 'blotting': 657,\n",
              " 'utterly': 658,\n",
              " 'high': 659,\n",
              " 'world': 660,\n",
              " 'people': 661,\n",
              " 'keep': 662,\n",
              " 'sit': 663,\n",
              " 'before': 664,\n",
              " 'open': 665,\n",
              " 'ah': 666,\n",
              " 'demon': 667,\n",
              " 'theirs': 668,\n",
              " 'interlock': 669,\n",
              " 'sadder': 670,\n",
              " 'hope': 671,\n",
              " 'tonight': 672,\n",
              " 'wait': 673,\n",
              " 'give': 674,\n",
              " 'hand': 675,\n",
              " 'under': 676,\n",
              " 'family': 677,\n",
              " 'youthful': 678,\n",
              " 'forms': 679,\n",
              " 'faces': 680,\n",
              " 'hourly': 681,\n",
              " 'life': 682,\n",
              " 'otherwise': 683,\n",
              " 'would': 684,\n",
              " 'heard': 685,\n",
              " 'seem': 686,\n",
              " 'childishness': 687,\n",
              " 'wouldnt': 688,\n",
              " 'strangely': 689,\n",
              " 'anything': 690,\n",
              " 'wish': 691,\n",
              " 'dark': 692,\n",
              " 'hes': 693,\n",
              " 'much': 694,\n",
              " 'better': 695,\n",
              " 'names': 696,\n",
              " 'barn': 697,\n",
              " 'smells': 698,\n",
              " 'wash': 699,\n",
              " 'ploughed': 700,\n",
              " 'ground': 701,\n",
              " 'disappeared': 702,\n",
              " 'ended': 703,\n",
              " 'far': 704,\n",
              " 'darkly': 705,\n",
              " 'present': 706,\n",
              " 'truest': 707,\n",
              " 'most': 708,\n",
              " 'fervently': 709,\n",
              " 'devoted': 710,\n",
              " 'nothing': 711,\n",
              " 'dreaming': 712,\n",
              " 'straight': 713,\n",
              " 'mountain': 714,\n",
              " 'fast': 715,\n",
              " 'likely': 716,\n",
              " 'regard': 717,\n",
              " 'sacred': 718,\n",
              " 'perish': 719,\n",
              " 'sign': 720,\n",
              " 'spose': 721,\n",
              " 'mallice': 722,\n",
              " 'small': 723,\n",
              " 'good': 724,\n",
              " 'growing': 725,\n",
              " 'wild': 726,\n",
              " 'tying': 727,\n",
              " 'sometimes': 728,\n",
              " 'authority': 729,\n",
              " 'yes': 730,\n",
              " 'go': 731,\n",
              " 'fell': 732,\n",
              " 'floor': 733,\n",
              " 'myself': 734,\n",
              " 'lying': 735,\n",
              " 'forward': 736,\n",
              " 'weakly': 737,\n",
              " 'handrail': 738,\n",
              " 'did': 739,\n",
              " 'rivulets': 740,\n",
              " 'seal': 741,\n",
              " 'yelp': 742,\n",
              " 'truth': 743,\n",
              " 'virtue': 744,\n",
              " 'humanity': 745,\n",
              " 'foreign': 746,\n",
              " 'soft': 747,\n",
              " 'dissyllables': 748,\n",
              " 'hog': 749,\n",
              " 'reeve': 750,\n",
              " 'sends': 751,\n",
              " 'luminary': 752,\n",
              " 'clock': 753,\n",
              " 'shut': 754,\n",
              " 'ill': 755,\n",
              " 'johns': 756,\n",
              " 'threatener': 757,\n",
              " 'mockery': 758,\n",
              " 'boast': 759,\n",
              " 'perhaps': 760,\n",
              " 'claim': 761,\n",
              " 'higher': 762,\n",
              " 'below': 763,\n",
              " 'plumes': 764,\n",
              " 'trailed': 765,\n",
              " 'dust': 766,\n",
              " 'windbreak': 767,\n",
              " 'clara': 768,\n",
              " 'robinson': 769,\n",
              " 'ghost': 770,\n",
              " 'amid': 771,\n",
              " 'entombing': 772,\n",
              " 'trees': 773,\n",
              " 'least': 774,\n",
              " 'solace': 775,\n",
              " 'changed': 776,\n",
              " 'staid': 777,\n",
              " 'farm': 778,\n",
              " 'thoughts': 779,\n",
              " 'palsied': 780,\n",
              " 'realms': 781,\n",
              " 'boreal': 782,\n",
              " 'pole': 783,\n",
              " 'favor': 784,\n",
              " 'fire': 785,\n",
              " 'own': 786,\n",
              " 'power': 787,\n",
              " 'seems': 788,\n",
              " 'undone': 789,\n",
              " 'difference': 790,\n",
              " 'mans': 791,\n",
              " 'affairs': 792,\n",
              " 'conquered': 793,\n",
              " 'scruples': 794,\n",
              " 'trembled': 795,\n",
              " 'stirred': 796,\n",
              " 'melancholy': 797,\n",
              " 'shrine': 798,\n",
              " 'mebbe': 799,\n",
              " 'wrong': 800,\n",
              " 'told': 801,\n",
              " 'twelvemonth': 802,\n",
              " 'rather': 803,\n",
              " 'tip': 804,\n",
              " 'table': 805,\n",
              " 'planets': 806,\n",
              " 'stretch': 807,\n",
              " 'highest': 808,\n",
              " 'feat': 809,\n",
              " 'sleep': 810,\n",
              " 'train': 811,\n",
              " 'bring': 812,\n",
              " 'chalkpile': 813,\n",
              " 'very': 814,\n",
              " 'smarty': 815,\n",
              " 'spoiled': 816,\n",
              " 'ten': 817,\n",
              " 'oclock': 818,\n",
              " 'eve': 819,\n",
              " 'need': 820,\n",
              " 'object': 821,\n",
              " 'hid': 822,\n",
              " 'jerk': 823,\n",
              " 'twitch': 824,\n",
              " 'suppose': 825,\n",
              " 'like': 826,\n",
              " 'thing': 827,\n",
              " 'ours': 828,\n",
              " 'lookoff': 829,\n",
              " 'faced': 830,\n",
              " 'half': 831,\n",
              " 'boring': 832,\n",
              " 'climbing': 833,\n",
              " 'isnt': 834,\n",
              " 'mortgage': 835,\n",
              " 'eden': 836,\n",
              " 'day': 837,\n",
              " 'upstairs': 838,\n",
              " 'downstairs': 839,\n",
              " 'lutes': 840,\n",
              " 'welltuned': 841,\n",
              " 'got': 842,\n",
              " 'hay': 843,\n",
              " 'rained': 844,\n",
              " 'three': 845,\n",
              " 'speak': 846,\n",
              " 'dialect': 847,\n",
              " 'voice': 848,\n",
              " 'tempt': 849,\n",
              " 'waters': 850,\n",
              " 'bed': 851,\n",
              " 'drear': 852,\n",
              " 'path': 853,\n",
              " 'grows': 854,\n",
              " 'july': 855,\n",
              " 'midnight': 856,\n",
              " 'child': 857,\n",
              " 'comes': 858,\n",
              " 'wasnt': 859,\n",
              " 'virgin': 860,\n",
              " 'wrapper': 861,\n",
              " 'deep': 862,\n",
              " 'mute': 863,\n",
              " 'ive': 864,\n",
              " 'crystal': 865,\n",
              " 'palace': 866,\n",
              " 'london': 867,\n",
              " 'imported': 868,\n",
              " 'left': 869,\n",
              " 'cool': 870,\n",
              " 'room': 871,\n",
              " 'studying': 872,\n",
              " 'genealogy': 873,\n",
              " 'israfel': 874,\n",
              " 'outspread': 875,\n",
              " 'lets': 876,\n",
              " 'gold': 877,\n",
              " 'buy': 878,\n",
              " 'creation': 879,\n",
              " 'youve': 880,\n",
              " 'estelles': 881,\n",
              " 'trap': 882,\n",
              " 'tutelar': 883,\n",
              " 'dread': 884,\n",
              " 'ominous': 885,\n",
              " 'stain': 886,\n",
              " 'tar': 887,\n",
              " 'turned': 888,\n",
              " 'try': 889,\n",
              " 'fathom': 890,\n",
              " 'faster': 891,\n",
              " 'slower': 892,\n",
              " 'chanced': 893,\n",
              " 'set': 894,\n",
              " 'lot': 895,\n",
              " 'record': 896,\n",
              " 'alder': 897,\n",
              " 'swamp': 898,\n",
              " 'legended': 899,\n",
              " 'tomb': 900,\n",
              " 'starlight': 901,\n",
              " 'pall': 902,\n",
              " 'exclaimed': 903,\n",
              " 'afar': 904,\n",
              " 'last': 905,\n",
              " 'nights': 906,\n",
              " 'kiting': 907,\n",
              " 'guide': 908,\n",
              " 'aright': 909,\n",
              " 'thinks': 910,\n",
              " 'makes': 911,\n",
              " 'weeks': 912,\n",
              " 'since': 913,\n",
              " 'snow': 914,\n",
              " 'mist': 915,\n",
              " 'ready': 916,\n",
              " 'hoary': 917,\n",
              " 'groans': 918,\n",
              " 'woe': 919,\n",
              " 'angels': 920,\n",
              " 'tenanted': 921,\n",
              " 'davis': 922,\n",
              " 'owned': 923,\n",
              " 'solid': 924,\n",
              " 'mica': 925,\n",
              " 'however': 926,\n",
              " 'bricks': 927,\n",
              " 'fervor': 928,\n",
              " 'lute': 929,\n",
              " 'for—montreal': 930,\n",
              " 'indians': 931,\n",
              " 'myth': 932,\n",
              " 'chicamoztoc': 933,\n",
              " 'fair': 934,\n",
              " 'swish': 935,\n",
              " 'others': 936,\n",
              " 'woman': 937,\n",
              " 'afterward': 938,\n",
              " 'pallor': 939,\n",
              " 'mistrust': 940,\n",
              " 'whir': 941,\n",
              " 'castles': 942,\n",
              " 'used': 943,\n",
              " 'build': 944,\n",
              " 'air': 945,\n",
              " 'witchs': 946,\n",
              " 'motto': 947,\n",
              " 'anyway': 948,\n",
              " 'start': 949,\n",
              " 'lately': 950,\n",
              " 'slept': 951,\n",
              " 'apathy': 952,\n",
              " 'dropped': 953,\n",
              " 'unwilling': 954,\n",
              " 'explain': 955,\n",
              " 'point': 956,\n",
              " 'tottering': 957,\n",
              " 'across': 958,\n",
              " 'sill': 959,\n",
              " 'hardest': 960,\n",
              " 'hue': 961,\n",
              " 'sing': 962,\n",
              " 'along': 963,\n",
              " 'toteroad': 964,\n",
              " 'oh': 965,\n",
              " 'loom': 966,\n",
              " 'israfeli': 967,\n",
              " 'despisest': 968,\n",
              " 'feet': 969,\n",
              " 'berries': 970,\n",
              " 'shining': 971,\n",
              " 'scarlet': 972,\n",
              " 'red': 973,\n",
              " 'jupiter': 974,\n",
              " 'pushed': 975,\n",
              " 'striven': 976,\n",
              " 'godliness': 977,\n",
              " 'throne': 978,\n",
              " 'few': 979,\n",
              " 'peckerfretted': 980,\n",
              " 'apple': 981,\n",
              " 'arose': 982,\n",
              " 'duplicate': 983,\n",
              " 'horn': 984,\n",
              " 'estelle': 985,\n",
              " 'housework': 986,\n",
              " 'board': 987,\n",
              " 'dawn': 988,\n",
              " 'goes': 989,\n",
              " 'leak': 990,\n",
              " 'emptied': 991,\n",
              " 'forty': 992,\n",
              " 'gnaw': 993,\n",
              " 'posts': 994,\n",
              " 'fences': 995,\n",
              " 'wilderness': 996,\n",
              " 'sorry': 997,\n",
              " 'road': 998,\n",
              " 'tender': 999,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(word2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4-vBgl2RYdl",
        "outputId": "02b6ea8c-1769-41bd-9d81-26f302d2676e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2555"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the data into integer format. This is what we need to index our A and oour Pi."
      ],
      "metadata": {
        "id": "uvnUPo8_SDGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert data into integer format\n",
        "train_text_int = []\n",
        "test_text_int = []\n",
        "\n",
        "for text in train_text:\n",
        "  tokens = text.split()\n",
        "  line_as_int = [word2idx[token] for token in tokens]\n",
        "  train_text_int.append(line_as_int)\n",
        "\n",
        "for text in test_text:\n",
        "  tokens = text.split()\n",
        "  \"\"\"\n",
        "  The difference here is that it is possible that not every word appear in the\n",
        "  test set, so we can't only try to index to our idx dictionary. Instead we use\n",
        "  get function and when we can't find the word, we return 0. This corresponds to\n",
        "  the unknown token\n",
        "  \"\"\"\n",
        "  line_as_int = [word2idx.get(token, 0) for token in tokens]\n",
        "  test_text_int.append(line_as_int)"
      ],
      "metadata": {
        "id": "23skva0xRayr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text_int[100:105]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_LxEhEqSMvN",
        "outputId": "a2e631af-a62e-4723-950d-34af988195e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[149, 365, 366],\n",
              " [182, 43, 60, 367, 368, 369],\n",
              " [260, 370, 371, 52, 372, 373],\n",
              " [374, 375, 376, 374, 377, 378],\n",
              " [115, 13, 379, 182, 31, 380, 31, 13, 381]]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The zeroes in the test set are unknown words."
      ],
      "metadata": {
        "id": "DXXuJNc-TPst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_text_int[100:105]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFxVHWuQSZxr",
        "outputId": "e1cd2808-8cda-4c2f-9939-90d27d43d059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[32, 181, 0, 71, 181],\n",
              " [666, 58, 667, 335, 500, 171, 100],\n",
              " [100, 148, 36, 850, 31, 36, 0, 280],\n",
              " [214, 128, 786, 778, 693, 0, 115, 41, 71, 2197],\n",
              " [1384, 31, 0, 441, 724, 1014, 71, 490, 38]]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are ready to build our A and Pi matrices which will represent our Markov Model.\n",
        "\n",
        "It's important to remember that we don't just have 1 Markov Model, we'll have as many as there are classes. Since we have 2 classes, we'll have 2 As and 2 Pis."
      ],
      "metadata": {
        "id": "jpP-jctbTOs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize A and Pi matrices - for both classes\n",
        "\n",
        "# lenght of idx: the vocabulary size\n",
        "V = len(word2idx)\n",
        "\"\"\"\n",
        "We initiliaze each of these arrays to all ones. The reason for that is that we\n",
        "are going to be using Add-One Smoothing, so these 1s are the initial fake counts\n",
        "for each initial word and each transition.\n",
        "\"\"\"\n",
        "A0 = np.ones((V, V))\n",
        "pi0 = np.ones(V)\n",
        "\n",
        "A1 = np.ones((V, V))\n",
        "pi1 = np.ones(V)"
      ],
      "metadata": {
        "id": "IqsUxAzvS80M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we populate the As and the Pis with the appropriate counts from the training set."
      ],
      "metadata": {
        "id": "SYha5JX2Z2A0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute counts for A and pi\n",
        "def compute_counts(text_as_int, A, pi):\n",
        "  # here each element is a line of a poem represent by a list of ints\n",
        "  for tokens in text_as_int:\n",
        "    # This variable will help us keep track if we are populating A or Pi\n",
        "    last_idx = None\n",
        "    for idx in tokens:\n",
        "      if last_idx is None:\n",
        "        # it's the first word in a sequence\n",
        "        pi[idx] += 1\n",
        "      else:\n",
        "        # the last word exists, so count a transition (one word to the next)\n",
        "        A[last_idx, idx] += 1\n",
        "\n",
        "      # update last idx\n",
        "      last_idx = idx\n",
        "\n",
        "# only the samples of class 0\n",
        "compute_counts([t for t, y in zip(train_text_int, Ytrain) if y == 0], A0, pi0)\n",
        "# only the samples of class 1\n",
        "compute_counts([t for t, y in zip(train_text_int, Ytrain) if y == 1], A1, pi1)"
      ],
      "metadata": {
        "id": "l_to2q7-Z0hN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we normalize A and Pi so they are valid probability matrices.\n"
      ],
      "metadata": {
        "id": "OEDqxuWMbeeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A0 /= A0.sum(axis=1, keepdims=True)\n",
        "pi0 /=  pi0.sum()\n",
        "\"\"\"\n",
        "keepdims = True ensures that the sum is still 2D, which is required for the\n",
        "division to broadcast correctly  in numpy.\n",
        "\n",
        "For Pi there is no need to do this since it's just a 1D array.\n",
        "\"\"\"\n",
        "A1 /= A1.sum(axis=1, keepdims=True)\n",
        "pi1 /=  pi1.sum()"
      ],
      "metadata": {
        "id": "Btjj5YOtbdGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Log A and Pi since we don't need the actual probs\n",
        "logA0 = np.log(A0)\n",
        "logpi0 = np.log(pi0)\n",
        "\n",
        "logA1 = np.log(A1)\n",
        "logpi1 = np.log(pi1)"
      ],
      "metadata": {
        "id": "7VR40UD6byXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute priors\n",
        "# How many samples belong to class zero and one in the training set.\n",
        "count0 = sum(y == 0 for y in Ytrain)\n",
        "count1 = sum(y == 1 for y in Ytrain)\n",
        "total = len(Ytrain)\n",
        "# compute the prior probabilites, p0 and p1\n",
        "p0 = count0  / total\n",
        "p1 = count1 / total\n",
        "logp0 = np.log(p0)\n",
        "logp1 = np.log(p1)\n",
        "p0, p1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7VBSQ3wcap7",
        "outputId": "19f7f5c0-caab-420d-d5a2-3f2fe14ca631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6674922600619195, 0.33250773993808047)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a classifier\n",
        "class Classifier:\n",
        "  # constructor\n",
        "  def __init__(self, logAs, logPis, logPriors):\n",
        "    self.logAs = logAs\n",
        "    self.logPis = logPis\n",
        "    self.logPriors = logPriors\n",
        "    self.K = len(logPriors) # number of classes\n",
        "\n",
        "  def _compute_log_likelihood(self, input_, class_):\n",
        "    logA = self.logAs[class_]\n",
        "    logPi = self.logPis[class_]\n",
        "\n",
        "    last_idx = None\n",
        "    logprob = 0\n",
        "    for idx in input_:\n",
        "      if last_idx is None:\n",
        "        # it's the first token\n",
        "        logprob += logPi[idx]\n",
        "      else:\n",
        "        logprob += logA[last_idx, idx]\n",
        "\n",
        "      # update last_idx\n",
        "      last_idx = idx\n",
        "\n",
        "    return logprob\n",
        "\n",
        "  def predict(self, inputs):\n",
        "    predictions = np.zeros(len(inputs))\n",
        "    for i, input in enumerate(inputs):\n",
        "      posteriors = [self._compute_log_likelihood(input, c) + self.logPriors[c] \\\n",
        "                    for c in range(self.K)]\n",
        "      pred = np.argmax(posteriors)\n",
        "      predictions[i] = pred\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "fELo22wKdQuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# each array must be in order since classes are assumed to index these lists\n",
        "clf = Classifier([logA0, logA1], [logpi0, logpi1], [logp0, logp1])"
      ],
      "metadata": {
        "id": "CrhY2OUZelSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ptrain = clf.predict(train_text_int)\n",
        "print(f\"Train acc: {np.mean(Ptrain==Ytrain)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mM8QATUXfz06",
        "outputId": "81a8e018-7332-42d1-9655-56461c5b9853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train acc: 0.9944272445820433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ptest = clf.predict(test_text_int)\n",
        "print(f\"Test acc: {np.mean(Ptest == Ytest)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqj1_bCQgwIY",
        "outputId": "e80f073b-b78b-4e4b-8daf-f883be886822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test acc: 0.8051948051948052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score"
      ],
      "metadata": {
        "id": "-77d69gtg6WY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(Ytrain, Ptrain)\n",
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAa3J5lzg_tp",
        "outputId": "64451782-72c9-4844-94f2-227d48678b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1078,    0],\n",
              "       [   9,  528]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm_test = confusion_matrix(Ytest, Ptest)\n",
        "cm_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ-d11F4hJTU",
        "outputId": "06b8561e-952a-4c34-d90c-83b857558eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[346,  12],\n",
              "       [ 93,  88]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(Ytrain, Ptrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEwu1NLbhPaH",
        "outputId": "602d5ac2-0f72-4aba-ee14-00fab9b14eb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9915492957746479"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(Ytest, Ptest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IvcDAHzhSvX",
        "outputId": "f0d4bd4d-8149-4f00-a490-586a0530316d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6263345195729537"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    }
  ]
}